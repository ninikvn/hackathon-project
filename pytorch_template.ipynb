{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninikvn/hackathon-project/blob/main/pytorch_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xg4Dqbg6p0US"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import ast\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"simulated_cancer_patients.csv\")\n",
        "df['mutated_hugoGeneSymbols'] = df['mutated_hugoGeneSymbols'].apply(ast.literal_eval)\n",
        "\n",
        "all_genes = sorted(set(g for genes in df['mutated_hugoGeneSymbols'] for g in genes))\n",
        "gene_to_index = {gene: i for i, gene in enumerate(all_genes)}\n",
        "n_patients, n_genes = len(df), len(all_genes)\n",
        "\n",
        "mutation_matrix = torch.zeros((n_patients, n_genes), dtype=torch.uint8)\n",
        "for i, gene_list in enumerate(df['mutated_hugoGeneSymbols']):\n",
        "    for gene in gene_list:\n",
        "        mutation_matrix[i, gene_to_index[gene]] = 1\n",
        "\n",
        "# === Encode cancer types as labels ===\n",
        "df['cancerType'] = df['cancerType'].astype('category')\n",
        "cancer_labels = torch.tensor(df['cancerType'].cat.codes.values)\n",
        "label_mapping = dict(enumerate(df['cancerType'].cat.categories))\n",
        "\n",
        "# === Train/test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    mutation_matrix, cancer_labels, test_size=0.2, stratify=cancer_labels, random_state=42\n",
        ")\n",
        "\n",
        "# === Save everything ===\n",
        "\n",
        "# Inputs and labels\n",
        "torch.save(X_train, \"X_train.pt\")\n",
        "torch.save(y_train, \"y_train.pt\")\n",
        "torch.save(X_test, \"X_test.pt\")\n",
        "torch.save(y_test, \"y_test.pt\")\n",
        "\n",
        "# Optional: save as datasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "torch.save(train_dataset, \"train_dataset.pt\")\n",
        "torch.save(test_dataset, \"test_dataset.pt\")\n",
        "\n",
        "# Save label mapping and gene list\n",
        "with open(\"cancer_label_mapping.json\", \"w\") as f:\n",
        "    json.dump(label_mapping, f)\n",
        "\n",
        "with open(\"gene_index.json\", \"w\") as f:\n",
        "    json.dump(gene_to_index, f)\n",
        "\n",
        "print(\"âœ… Data saved:\")\n",
        "print(\"- X_train.pt / y_train.pt\")\n",
        "print(\"- X_test.pt / y_test.pt\")\n",
        "print(\"- train_dataset.pt / test_dataset.pt\")\n",
        "print(\"- cancer_label_mapping.json / gene_index.json\")\n"
      ],
      "metadata": {
        "id": "Qv6T3bg9xmfa",
        "outputId": "fe25215e-c75d-4d93-90db-d884a3b924c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'simulated_cancer_patients.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3259691865>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"simulated_cancer_patients.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mutated_hugoGeneSymbols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mutated_hugoGeneSymbols'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mall_genes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgenes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mutated_hugoGeneSymbols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgene_to_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mgene\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_genes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'simulated_cancer_patients.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Goowmhe18CdD"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_inputs = None\n",
        "train_labels= None\n",
        "test_inputs = None\n",
        "test_labels=None\n",
        "\n",
        "class cBioPortalDataset(Dataset):\n",
        "  \"\"\"\n",
        "    Every Pytorch Dataset needs an __init__, __len__, and __getitem__\n",
        "    These methods are used to get and batch the data using a DataLoader later\n",
        "  \"\"\"\n",
        "  def __init__(self, images, labels):\n",
        "    self.images = torch.Tensor(images)\n",
        "    self.labels = torch.Tensor(labels)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.images[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "train_dataset = cBioPortalDataset(train_inputs, train_labels)\n",
        "test_dataset = cBioPortalDataset(test_inputs, test_labels)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SYjEFmIviMw",
        "outputId": "507e4ee5-9bef-4764-cc8b-ef7f6af42f54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [00:01, 40.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on testing set after epoch 0: 0.9364855885505676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [00:01, 53.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on testing set after epoch 1: 0.9549247026443481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [00:01, 50.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on testing set after epoch 2: 0.9593949317932129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [00:01, 52.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on testing set after epoch 3: 0.9654256701469421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [00:01, 43.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on testing set after epoch 4: 0.9686263799667358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [00:01, 52.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on testing set after epoch 5: 0.9700155258178711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [00:01, 51.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on testing set after epoch 6: 0.9710897207260132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [00:01, 49.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on testing set after epoch 7: 0.9715701341629028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [00:02, 27.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on testing set after epoch 8: 0.9713448286056519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [00:01, 39.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on testing set after epoch 9: 0.9723971486091614\n",
            "\n",
            "Model(\n",
            "  (layer1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (layer2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (layer3): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "    \"\"\"\n",
        "    The model class inherits from tf.keras.Model.\n",
        "    It stores the trainable weights as attributes.\n",
        "    \"\"\"\n",
        "    super(Model, self).__init__(**kwargs)\n",
        "\n",
        "    self.layer1 = torch.nn.Linear(784, 256)\n",
        "    self.layer2 = torch.nn.Linear(256, 128)\n",
        "    self.layer3 = torch.nn.Linear(128, 10)\n",
        "\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    \"\"\"\n",
        "    Forward pass, predicts labels given an input image using fully connected layers\n",
        "    :return: the probabilites of each label\n",
        "    \"\"\"\n",
        "\n",
        "    out1 = self.layer1(inputs)\n",
        "    out1 = self.relu(out1)\n",
        "    out2 = self.layer2(out1)\n",
        "    out2 = self.relu(out2)\n",
        "    out3 = self.layer3(out2)\n",
        "    prbs = self.softmax(out3)\n",
        "    return prbs\n",
        "\n",
        "  def loss(self, predictions, labels):\n",
        "    \"\"\"\n",
        "    Calculates the model loss\n",
        "    :return: the loss of the model as a tensor\n",
        "    \"\"\"\n",
        "    nll_comps = -labels * torch.log(torch.clip(predictions,1e-10,1.0))\n",
        "    return torch.mean(torch.sum(nll_comps, axis=[1]))\n",
        "\n",
        "  def accuracy(self, predictions, labels):\n",
        "    \"\"\"\n",
        "    Calculates the model accuracy\n",
        "    :return: the accuracy of the model as a tensor\n",
        "    \"\"\"\n",
        "    pred_classes = torch.argmax(predictions, 1)\n",
        "    true_classes = torch.argmax(labels, 1)\n",
        "    correct_prediction = torch.eq(pred_classes, true_classes)\n",
        "    return torch.mean(torch.Tensor(correct_prediction).to(torch.float32))\n",
        "\n",
        "################################################################################\n",
        "\n",
        "model = Model()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for j in range(epochs):\n",
        "  for batch_idx, (input, label) in tqdm(enumerate(train_loader)):\n",
        "    input = torch.reshape(input, (len(input),-1))\n",
        "    y_pred = model(input)\n",
        "    loss = model.loss(y_pred, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "  test_acc = 0\n",
        "  for batch_idx, (input, label) in enumerate(test_loader):\n",
        "    input = torch.reshape(input, (len(input),-1))\n",
        "    test_acc += model.accuracy(model(input), label)\n",
        "  print(f\"Accuracy on testing set after epoch {j}: {test_acc/len(test_loader)}\")\n",
        "print()\n",
        "print(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}